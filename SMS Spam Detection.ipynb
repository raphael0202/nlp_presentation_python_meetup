{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-01-21 10:55:51--  https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
      "Résolution de archive.ics.uci.edu (archive.ics.uci.edu)… 128.195.10.249\n",
      "Connexion à archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 203415 (199K) [application/zip]\n",
      "Sauvegarde en : « smsspamcollection.zip.1 »\n",
      "\n",
      "smsspamcollection.z 100%[===================>] 198,65K   127KB/s    in 1,6s    \n",
      "\n",
      "2017-01-21 10:55:54 (127 KB/s) — « smsspamcollection.zip.1 » sauvegardé [203415/203415]\n",
      "\n",
      "Archive:  smsspamcollection.zip\n",
      "  inflating: SMSSpamCollection       \n",
      "  inflating: readme                  \n",
      "presentation_nlp_python.md  SMSSpamCollection\t     'SMS Spam Detection.ipynb'\n",
      "readme\t\t\t    smsspamcollection.zip.1\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
    "!unzip smsspamcollection.zip && rm smsspamcollection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "presentation_nlp_python.md  SMSSpamCollection\t     'SMS Spam Detection.ipynb'\r\n",
      "readme\t\t\t    smsspamcollection.zip.1\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "target_names = []\n",
    "target = []\n",
    "\n",
    "with open('SMSSpamCollection', 'r') as f:\n",
    "    for line in f:\n",
    "        label, text = line.split(maxsplit=1)\n",
    "        \n",
    "        try:\n",
    "            target_index = target_names.index(label)\n",
    "            \n",
    "        except ValueError:\n",
    "            target_names.append(label)\n",
    "            target_index = len(target_names) - 1\n",
    "        \n",
    "        target.append(target_index)\n",
    "        data.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available targets: ['ham', 'spam']\n",
      "Total number of items: 5574\n",
      "Number of items in each class: Counter({0: 4827, 1: 747})\n"
     ]
    }
   ],
   "source": [
    "print(\"Available targets: {}\".format(target_names))\n",
    "print(\"Total number of items: {}\".format(len(data)))\n",
    "print(\"Number of items in each class: {}\".format(Counter(target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 'ham'\n",
      "text: 'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "'\n"
     ]
    }
   ],
   "source": [
    "print(\"Class: '{}'\\ntext: '{}'\".format(target_names[target[0]], data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "We need to split our data between the *training set* and the *test set*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_train (4180), X_test (1394), y_train (4180), y_test (1394)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target)\n",
    "print(\"Length of X_train ({}), X_test ({}), \"\n",
    "      \"y_train ({}), y_test ({})\".format(len(X_train), len(X_test), len(y_train), len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words representation\n",
    "\n",
    "In order to perform text classification, we have to turn the text documents into numerical feature vectors that can be used by the classification algorithm. The easiest way is to use a **bag of words representation**.\n",
    "\n",
    "- assign a fixed integer `j` to each word occuring in the training set\n",
    "- for each document `i`, count the number of occurrences of word `w` and put it in $X[i, j]$ where `j` is the id of word `w`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4180, 7483)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X_train_counts = vec.fit_transform(X_train)\n",
    "print(X_train_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alone': 906,\n",
       " 'bro': 1480,\n",
       " 'camcorder': 1585,\n",
       " 'ducking': 2419,\n",
       " 'moves': 4462,\n",
       " 'pai': 4883,\n",
       " 'purse': 5325,\n",
       " 'relatives': 5487,\n",
       " 'trade': 6775,\n",
       " 'yuou': 7470}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(x for idx, x in enumerate(vec.vocabulary_.items()) if idx < 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tf_transformer = TfidfTransformer()\n",
    "X_train_tf = tf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 1262, 1: 132})\n"
     ]
    }
   ],
   "source": [
    "X_test_counts = vec.transform(X_test)\n",
    "X_test_tf = tf_transformer.transform(X_test_counts)\n",
    "predictions = clf.predict(X_test_tf)\n",
    "print(Counter(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.96      1.00      0.98      1217\n",
      "       spam       0.98      0.73      0.84       177\n",
      "\n",
      "avg / total       0.97      0.96      0.96      1394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
